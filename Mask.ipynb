{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPBgrWQZ2vT9I9Vme9vD1wf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"OpCQExOkOyfP"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# import os\n","# import cv2\n","# import numpy as np\n","# from torch.utils.data import Dataset, DataLoader\n","\n","# class ImageDataset(Dataset):\n","#     def __init__(self, root_dir):\n","#         self.image_paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith('.tif')]\n","\n","#     def __len__(self):\n","#         return len(self.image_paths)\n","\n","#     def __getitem__(self, idx):\n","#         image_path = self.image_paths[idx]\n","#         image = cv2.imread(image_path)\n","#         return image, image_path\n","\n","# # Assuming you have a data loader that loads images from a directory\n","# data_loader = DataLoader(ImageDataset('/content/drive/MyDrive/Data/0'), batch_size=1, shuffle=False)\n","# output_dir = '/content/drive/MyDrive/Data/0_musk'\n","\n","# if not os.path.exists(output_dir):\n","#     os.makedirs(output_dir)\n","\n","# for i, (image, image_path) in enumerate(data_loader):\n","#     # Apply binary threshold on grayscale image\n","#     img = cv2.cvtColor(image.squeeze().numpy(), cv2.COLOR_RGB2GRAY) # Squeeze and convert to numpy array\n","#     _, binary_img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n","#     # Save binary image with the same name as original image\n","#     filename = os.path.splitext(os.path.basename(image_path[0]))[0]\n","#     output_path = os.path.join(output_dir, f'{filename}.tif')\n","#     cv2.imwrite(output_path, binary_img)"],"metadata":{"id":"LxReNfQWPLsM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import os\n","# import cv2\n","# import numpy as np\n","# from skimage.filters import frangi\n","# from torch.utils.data import Dataset, DataLoader\n","\n","# class ImageDataset(Dataset):\n","#     def __init__(self, root_dir):\n","#         self.image_paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith('.tif')]\n","\n","#     def __len__(self):\n","#         return len(self.image_paths)\n","\n","#     def __getitem__(self, idx):\n","#         image_path = self.image_paths[idx]\n","#         image = cv2.imread(image_path)\n","#         return image, image_path\n","\n","# # Assuming you have a data loader that loads images from a directory\n","# data_loader = DataLoader(ImageDataset('/content/drive/MyDrive/Data/1'), batch_size=1, shuffle=False)\n","# output_dir = '/content/drive/MyDrive/Data/1_musk'\n","\n","# if not os.path.exists(output_dir):\n","#     os.makedirs(output_dir)\n","\n","# for i, (image, image_path) in enumerate(data_loader):\n","#     # Apply Frangi filter to enhance blood vessels\n","#     img = cv2.cvtColor(image.squeeze().numpy(), cv2.COLOR_RGB2GRAY) # Squeeze and convert to numpy array\n","#     frangi_img = frangi(img, scale_range=(1, 10), scale_step=2, alpha=0.5, beta=0.5, gamma=15, black_ridges=False)\n","#     # Normalize image\n","#     frangi_img = (frangi_img - np.min(frangi_img)) / (np.max(frangi_img) - np.min(frangi_img)) * 255\n","#     # Convert to uint8\n","#     frangi_img = frangi_img.astype(np.uint8)\n","#     # Apply binary thresholding to create a binary image\n","#     _, binary_img = cv2.threshold(frangi_img, 0, 255, cv2.THRESH_BINARY)\n","#     # Invert binary image\n","#     binary_img = cv2.bitwise_not(binary_img)\n","#     # Save binary image with the same name as original image\n","#     filename = os.path.splitext(os.path.basename(image_path[0]))[0]\n","#     output_path = os.path.join(output_dir, f'{filename}.tif')\n","#     cv2.imwrite(output_path, binary_img)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b_NNxaojhyEv","executionInfo":{"status":"ok","timestamp":1678524424654,"user_tz":-360,"elapsed":33491,"user":{"displayName":"Miraj Hossain Shawon","userId":"08980054486899795507"}},"outputId":"34e68a3f-3eaf-4788-d9de-987e09e32060"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-31-94c367103f3f>:29: UserWarning: Use keyword parameter `sigmas` instead of `scale_range` and `scale_range` which will be removed in version 0.17.\n","  frangi_img = frangi(img, scale_range=(1, 10), scale_step=2, alpha=0.5, beta=0.5, gamma=15, black_ridges=False)\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","from skimage.filters import frangi\n","from torch.utils.data import Dataset, DataLoader\n","\n","class ImageDataset(Dataset):\n","    def __init__(self, root_dir):\n","        self.image_paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith('.tif')]\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        image_path = self.image_paths[idx]\n","        image = cv2.imread(image_path)\n","        image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # convert image to grayscale\n","        return image_gray, image_path\n","\n","# Assuming you have a data loader that loads images from a directory\n","data_loader = DataLoader(ImageDataset('/content/drive/MyDrive/Data/1'), batch_size=1, shuffle=False)\n","output_dir = '/content/drive/MyDrive/Data/1_musk'\n","\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","for i, (image, image_path) in enumerate(data_loader):\n","    # Apply Frangi filter to enhance blood vessels\n","    frangi_img = frangi(image.squeeze().numpy(), scale_range=(1, 10), scale_step=2, alpha=0.5, beta=0.5, gamma=15, black_ridges=False)\n","    # Normalize image\n","    frangi_img = (frangi_img - np.min(frangi_img)) / (np.max(frangi_img) - np.min(frangi_img)) * 255\n","    # Convert to uint8\n","    frangi_img = frangi_img.astype(np.uint8)\n","    # Apply binary thresholding to create a binary image\n","    _, binary_img = cv2.threshold(frangi_img, 0, 255, cv2.THRESH_BINARY)\n","    # Invert binary image\n","    binary_img = cv2.bitwise_not(binary_img)\n","    # Save binary image with the same name as original image\n","    filename = os.path.splitext(os.path.basename(image_path[0]))[0]\n","    output_path = os.path.join(output_dir, f'{filename}.tif')\n","    cv2.imwrite(output_path, binary_img)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IsRLeRaErdnp","executionInfo":{"status":"ok","timestamp":1678525540346,"user_tz":-360,"elapsed":63973,"user":{"displayName":"Miraj Hossain Shawon","userId":"08980054486899795507"}},"outputId":"7d6ae11e-387a-4367-f190-1737cdb981f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-3-73e38ecbd89e>:29: UserWarning: Use keyword parameter `sigmas` instead of `scale_range` and `scale_range` which will be removed in version 0.17.\n","  frangi_img = frangi(image.squeeze().numpy(), scale_range=(1, 10), scale_step=2, alpha=0.5, beta=0.5, gamma=15, black_ridges=False)\n"]}]},{"cell_type":"markdown","source":["Gray image\n"],"metadata":{"id":"el4BJ22KKAL6"}},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","from skimage.filters import frangi\n","from torch.utils.data import Dataset, DataLoader\n","\n","class ImageDataset(Dataset):\n","    def __init__(self, root_dir):\n","        self.image_paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith('.tif')]\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        image_path = self.image_paths[idx]\n","        image = cv2.imread(image_path)\n","        return image, image_path\n","\n","# Assuming you have a data loader that loads images from a directory\n","data_loader = DataLoader(ImageDataset('/content/drive/MyDrive/Data/1'), batch_size=1, shuffle=False)\n","output_dir = '/content/drive/MyDrive/Data/1_musk'\n","\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","for i, (image, image_path) in enumerate(data_loader):\n","    # Convert to grayscale\n","    gray_img = cv2.cvtColor(image.squeeze().numpy(), cv2.COLOR_RGB2GRAY)\n","    \n","    # # Apply Frangi filter to enhance blood vessels\n","    # frangi_img = frangi(gray_img, scale_range=(1, 10), scale_step=2, alpha=0.5, beta=0.5, gamma=15, black_ridges=False)\n","    \n","    # # Normalize image\n","    # frangi_img = (frangi_img - np.min(frangi_img)) / (np.max(frangi_img) - np.min(frangi_img)) * 255\n","    \n","    # # Convert to uint8\n","    # frangi_img = frangi_img.astype(np.uint8)\n","    \n","    # # Apply binary thresholding to create a binary image\n","    # _, binary_img = cv2.threshold(frangi_img, 0, 255, cv2.THRESH_BINARY)\n","    \n","    # # Invert binary image\n","    # binary_img = cv2.bitwise_not(binary_img)\n","    \n","    # Save binary image with the same name as original image\n","    filename = os.path.splitext(os.path.basename(image_path[0]))[0]\n","    output_path = os.path.join(output_dir, f'{filename}.tif')\n","    cv2.imwrite(output_path, gray_img)\n"],"metadata":{"id":"ij6KBm8H8dMA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Enhance"],"metadata":{"id":"duKAT1XilIaj"}},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","\n","# Define the input and output directories\n","input_dir = '/content/drive/MyDrive/Data/1_musk'\n","output_dir = '/content/drive/MyDrive/Data/1_ROI'\n","\n","# Define the structuring element for morphological operations\n","se = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n","\n","# Loop through each image in the input directory\n","for filename in os.listdir(input_dir):\n","    # Read in the input image and convert to grayscale\n","    gray = cv2.imread(os.path.join(input_dir, filename))\n","    \n","    # Apply a median filter to remove noise\n","    #gray = cv2.medianBlur(img, 5)\n","\n","    # Apply top-hat transform to enhance the vessel-like structures\n","    # tophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, se)\n","\n","    # Normalize the image to enhance contrast\n","    norm = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8UC1)\n","\n","    # Threshold the image to remove low-intensity pixels\n","    _,thresh = cv2.threshold(norm, 255, 255, cv2.THRESH_BINARY)\n","\n","    # Apply a closing operation to remove small gaps in the vessel walls\n","    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, se)\n","\n","    # Subtract the closed image from the original image to remove the vessel light reflex\n","    removed = cv2.subtract(gray, closed)\n","\n","    # Save the result to the output directory\n","    output_filename = os.path.join(output_dir, filename)\n","    cv2.imwrite(output_filename, removed)\n"],"metadata":{"id":"Wv_av_NnMm8l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["gabor\n"],"metadata":{"id":"QLKDOXMilA_E"}},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","\n","# Define the input and output directories\n","input_dir = '/content/drive/MyDrive/Data/1_musk'\n","output_dir = '/content/drive/MyDrive/Data/1_Gabor'\n","\n","# Define the Gabor filter parameters\n","ksize = (21, 21)\n","sigma = 5\n","theta = 0\n","lambd = 10\n","gamma = 0.5\n","psi = 0\n","\n","# Define the structuring element for morphological operations\n","se = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n","\n","# Loop through each image in the input directory\n","for filename in os.listdir(input_dir):\n","    # Read in the input image and convert to grayscale\n","    img = cv2.imread(os.path.join(input_dir, filename))\n","    #gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","    # Apply a median filter to remove noise\n","    #gray = cv2.medianBlur(gray, 5)\n","\n","    # Apply Gabor filter to enhance the vessel-like structures\n","    gabor = cv2.getGaborKernel(ksize, sigma, theta, lambd, gamma, psi, ktype=cv2.CV_32F)\n","    gabor_filtered = cv2.filter2D(img, cv2.CV_8UC1, gabor)\n","    # Apply top-hat transform to enhance the vessel-like structures\n","    tophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, se)\n","\n","    # Save the result to the output directory\n","    output_filename = os.path.join(output_dir, filename)\n","    cv2.imwrite(output_filename, tophat)"],"metadata":{"id":"ADFCtY5NMZ0-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Gussian"],"metadata":{"id":"KCmwPTNplRXx"}},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","\n","# Define the input and output directories\n","input_dir = '/content/drive/MyDrive/Data/1_ROI'\n","output_dir = '/content/drive/MyDrive/Data/1_Gabor'\n","\n","# Define the size of the Gaussian kernel\n","kernel_size = (15, 15)\n","\n","# Define the structuring element for morphological operations\n","se = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))\n","\n","# Loop through each image in the input directory\n","for filename in os.listdir(input_dir):\n","    # Read in the input image and convert to grayscale\n","    img = cv2.imread(os.path.join(input_dir, filename))\n","    #gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","    # Apply a Gaussian filter to smooth the image\n","    smooth = cv2.GaussianBlur(img, kernel_size, 200)\n","\n","    # Apply the top-hat transform to enhance small features\n","    tophat = cv2.morphologyEx(gray - smooth, cv2.MORPH_TOPHAT, se)\n","\n","    # Save the result to the output directory\n","    output_filename = os.path.join(output_dir, filename)\n","    cv2.imwrite(output_filename, tophat)"],"metadata":{"id":"U5UOyLu2lS1v"},"execution_count":null,"outputs":[]}]}