{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN3a4ioXJrC9kApeaeiTy2g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"HuyG6pQ93Zqq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678554719391,"user_tz":-360,"elapsed":3107,"user":{"displayName":"Miraj Hossain Shawon","userId":"08980054486899795507"}},"outputId":"236a27c4-c4cd-4cf0-bdbd-2b7389d7ebac"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=1, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n","                               padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    \"\"\"Self-distillation based on resnet\"\"\"\n","\n","    def __init__(self, block, layers, branch_layers, num_classes=2):\n","        self.inplanes = 64\n","        super(ResNet, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n","                               bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        inplanes_head1 = self.inplanes\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n","        inplanes_head2 = self.inplanes\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n","        inplanes_head3 = self.inplanes\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n","        self.fc_main = nn.Linear(512 * block.expansion, num_classes)\n","\n","        # side branch 1\n","        self.inplanes = inplanes_head1\n","        self.sb11 = self._make_layer(block, 128, branch_layers[0][0], stride=2)\n","        self.sb12 = self._make_layer(block, 256, branch_layers[0][1], stride=2)\n","        self.sb13 = self._make_layer(block, 512, branch_layers[0][2], stride=2)\n","        self.fc_head1 = nn.Linear(512 * block.expansion, num_classes)\n","\n","        # side branch 2\n","        self.inplanes = inplanes_head2\n","        self.sb21 = self._make_layer(block, 256, branch_layers[1][0], stride=2)\n","        self.sb22 = self._make_layer(block, 512, branch_layers[1][1], stride=2)\n","        self.fc_head2 = nn.Linear(512 * block.expansion, num_classes)\n","\n","        # side branch 3\n","        self.inplanes = inplanes_head3\n","        self.sb31 = self._make_layer(block, 512, branch_layers[2][0], stride=2)\n","        self.fc_head3 = nn.Linear(512 * block.expansion, num_classes)\n","\n","        # CAM-attention\n","        self.cam_conv1 = nn.Conv2d(512 * block.expansion, num_classes, kernel_size=1, padding=0,\n","                                   bias=False)\n","        self.cam_bn1 = nn.BatchNorm2d(num_classes)\n","        self.cam_out = nn.Conv2d(num_classes, num_classes, kernel_size=1, padding=0,\n","                                 bias=False)\n","        self.gap = nn.AdaptiveAvgPool2d(1)\n","        self.cam_conv2 = nn.Conv2d(num_classes, 1, kernel_size=3, padding=1,\n","                                   bias=False)\n","        self.cam_bn2 = nn.BatchNorm2d(1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = node1 = self.layer1(x)\n","        x = node2 = self.layer2(x)\n","        x = node3 = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        # CAM branch\n","        cam1 = self.relu(self.cam_bn1(self.cam_conv1(x)))\n","        out_cam = self.gap(self.cam_out(cam1))\n","        out_cam = out_cam.view(out_cam.size(0), -1)\n","\n","        # main branch\n","        cam2 = self.sigmoid(self.cam_bn2(self.cam_conv2(cam1)))\n","        main_feature = x * cam2 + x\n","        m = self.gap(main_feature)\n","        m = m.view(m.size(0), -1)\n","        out_main = self.fc_main(m)\n","\n","        # side branch 1\n","        hide_feature1 = self.sb13(self.sb12(self.sb11(node1)))\n","        h1 = self.gap(hide_feature1)\n","        h1 = h1.view(h1.size(0), -1)\n","        side_out1 = self.fc_head1(h1)\n","\n","        # side branch 2\n","        hide_feature2 = self.sb22(self.sb21(node2))\n","        h2 = self.gap(hide_feature2)\n","        h2 = h2.view(h2.size(0), -1)\n","        side_out2 = self.fc_head2(h2)\n","\n","        # side branch 3\n","        hide_feature3 = self.sb31(node3)\n","        h3 = self.gap(hide_feature3)\n","        h3 = h3.view(h3.size(0), -1)\n","        side_out3 = self.fc_head3(h3)\n","\n","        return [out_cam, main_feature, out_main], [hide_feature1, side_out1], [hide_feature2, side_out2], [\n","            hide_feature3, side_out3]\n","\n","\n","        # Main  Branch1   Branch2  Branch3\n","        # 1.84GFlops  1.36GFlops  1.59GFlops 1.82GFlops   \n","\n","\n","def resnet18(num_classes, **kwargs):\n","    \"\"\"Constructs a ResNet-18 model.\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","    \"\"\"\n","    model = ResNet(BasicBlock, [2, 2, 2, 2], [[1, 1, 2], [1, 2], [2]], num_classes, **kwargs)\n","    return model\n","\n","\n","def resnet34(num_classes, **kwargs):\n","    \"\"\"Constructs a ResNet-34 model.\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","    \"\"\"\n","    model = ResNet(BasicBlock, [3, 4, 6, 3], [[2, 3, 3], [3, 3], [3]], num_classes, **kwargs)\n","    return model\n","\n","\n","def resnet50(num_classes, **kwargs):\n","    \"\"\"Constructs a ResNet-50 model.\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","    \"\"\"\n","    model = ResNet(Bottleneck, [3, 4, 6, 3], [[2, 3, 3], [3, 3], [3]], num_classes, **kwargs)\n","    return model\n","\n","\n","def resnet101(num_classes, **kwargs):\n","    \"\"\"Constructs a ResNet-101 model.\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","    \"\"\"\n","    model = ResNet(Bottleneck, [3, 4, 23, 3], [[2, 6, 3], [6, 3], [3]], num_classes, **kwargs)\n","    return model\n","\n","\n","def resnet152(num_classes, **kwargs):\n","    \"\"\"Constructs a ResNet-152 model.\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","    \"\"\"\n","    model = ResNet(Bottleneck, [3, 8, 36, 3], [[4, 12, 3], [12, 3], [3]], num_classes, **kwargs)\n","    return model\n","\n","\n","# if __name__ == '__main__':\n","#     import torch\n","#     import time\n","#     # from torchstat import stat\n","\n","#     # net = resnet50(num_classes=4)\n","#     # # stat(net, (3, 224, 224))\n","\n","#     # # Freeze some layers\n","#     # ct = 0\n","#     # for name, child in net.named_children():\n","#     #     ct += 1\n","#     #     if ct < 6:\n","#     #         for names, params in child.named_children():\n","#     #             params.requires_grad = False\n","#     N = 500\n","#     input = torch.randn(N, 3, 224 ,224).cuda()\n","#     net = resnet18(num_classes=2).cuda()\n","#     # stat(net, (3, 224, 224))\n","\n","#     torch.cuda.synchronize()\n","#     start = time.time()\n","\n","#     with torch.no_grad():\n","#         net(input)\n","    \n","#     torch.cuda.synchronize()\n","#     dur = time.time() - start\n","\n","#     print(dur / N)"],"metadata":{"id":"7Y5xpyS4pZtG","executionInfo":{"status":"ok","timestamp":1678555103601,"user_tz":-360,"elapsed":340,"user":{"displayName":"Miraj Hossain Shawon","userId":"08980054486899795507"}}},"execution_count":102,"outputs":[]},{"cell_type":"code","execution_count":104,"metadata":{"id":"GNMvHJwF3EfF","executionInfo":{"status":"ok","timestamp":1678555187288,"user_tz":-360,"elapsed":548,"user":{"displayName":"Miraj Hossain Shawon","userId":"08980054486899795507"}}},"outputs":[],"source":["model = ResNet(BasicBlock, [2, 2, 2, 2], [[1, 1, 2], [1, 2], [2]], num_classes=2)"]},{"cell_type":"code","source":["\n","\n","# import torch\n","\n","# import numpy as np\n","# import cv2\n","\n","\n","# class GradCAM(object):\n","\n","#     def __init__(self, net, layer_name):\n","#         self.net = net\n","#         self.layer_name = layer_name\n","#         self.feature = None\n","#         self.gradient = None\n","#         self.net.eval()\n","#         self.handlers = []\n","#         self._register_hook()\n","\n","#     def _get_features_hook(self, module, input, output):\n","#         self.feature = output\n","#         print(\"feature shape:{}\".format(output.size()))\n","\n","#     def _get_grads_hook(self, module, input_grad, output_grad):\n","#         \"\"\"\n","#         :param input_grad: tuple, input_grad[0]: None\n","#                                    input_grad[1]: weight\n","#                                    input_grad[2]: bias\n","#         :param output_grad:tuple\n","#         :return:\n","#         \"\"\"\n","#         self.gradient = output_grad[0]\n","\n","#     def _register_hook(self):\n","#         for (name, module) in self.net.named_modules():\n","#             if name == self.layer_name:\n","#                 self.handlers.append(module.register_forward_hook(self._get_features_hook))\n","#                 self.handlers.append(module.register_backward_hook(self._get_grads_hook))\n","\n","#     def remove_handlers(self):\n","#         for handle in self.handlers:\n","#             handle.remove()\n","\n","#     def __call__(self, inputs, index):\n","#         \"\"\"\n","#         :param inputs: [1,3,H,W]\n","#         :param index: class id\n","#         :return:\n","#         \"\"\"\n","#         self.net.zero_grad()\n","#         # inputs = torch.tensor(inputs, dtype=torch.float32)\n","#         output = self.net(inputs)[0][0]  # [1,num_classes]\n","#         if index is None:\n","#             index = np.argmax(output.cpu().data.numpy())\n","#         target = output[0][index]\n","#         target.backward()\n","\n","#         gradient = self.gradient[0].cpu().data.numpy()  # [C,H,W]\n","#         weight = np.mean(gradient, axis=(1, 2))  # [C]\n","\n","#         feature = self.feature[0].cpu().data.numpy()  # [C,H,W]\n","\n","#         cam = feature * weight[:, np.newaxis, np.newaxis]  # [C,H,W]\n","#         cam = np.sum(cam, axis=0)  # [H,W]\n","#         cam = np.maximum(cam, 0)  # ReLU\n","\n","#         cam -= np.min(cam)\n","#         cam /= np.max(cam)\n","#         # resize to 224*224\n","#         cam = cv2.resize(cam, (224, 224))\n","#         return cam\n","\n","class GradCAM(object):\n","\n","    def __init__(self, net, layer_name):\n","        self.net = net\n","        self.layer_name = layer_name\n","        self.feature = None\n","        self.gradient = None\n","        self.net.eval()\n","        self.handlers = []\n","        self._register_hook()\n","\n","    def _get_features_hook(self, module, input, output):\n","        self.feature = output\n","        print(\"feature shape:{}\".format(output.size()))\n","\n","    def _get_grads_hook(self, module, grad_input, grad_output):\n","        self.gradient = grad_output[0]\n","        print(\"gradient shape:{}\".format(grad_output[0].size()))\n","\n","    def _register_hook(self):\n","        for (name, module) in self.net.named_modules():\n","            if name == self.layer_name:\n","                self.handlers.append(module.register_forward_hook(self._get_features_hook))\n","                self.handlers.append(module.register_full_backward_hook(self._get_grads_hook))\n","\n","    def remove_handlers(self):\n","        for handle in self.handlers:\n","            handle.remove()\n","\n","    def __call__(self, inputs):\n","\n","        self.net.zero_grad()\n","        output = self.net(inputs)\n","        \n","        output = output[0] # select first tensor from the tuple\n","        output = torch.Tensor(output[0].unsqueeze(0))\n","        index = torch.argmax(output, dim=1)\n","        target = output[0, index]\n","        target.backward()\n","\n","        gradient = self.gradient.cpu().data.numpy()  # [C,H,W]\n","        weight = np.mean(gradient, axis=(1, 2))  # [C]\n","\n","        feature = self.feature.cpu().data.numpy()  # [C,H,W]\n","\n","        cam = feature * weight[:, np.newaxis, np.newaxis]  # [C,H,W]\n","        cam = np.sum(cam, axis=0)  # [H,W]\n","        cam = np.maximum(cam, 0)  # ReLU\n","\n","        cam -= np.min(cam)\n","        cam /= np.max(cam)\n","        # resize to 224*224\n","        cam = cv2.resize(cam, (224, 224))\n","        return cam\n","\n","\n"],"metadata":{"id":"3Z3Ww3-o3Yej","executionInfo":{"status":"ok","timestamp":1678558912314,"user_tz":-360,"elapsed":431,"user":{"displayName":"Miraj Hossain Shawon","userId":"08980054486899795507"}}},"execution_count":152,"outputs":[]},{"cell_type":"code","source":["\n","import torch\n","from torch import nn\n","import numpy as np\n","\n","\n","class GuidedBackPropagation(object):\n","\n","    def __init__(self, net):\n","        self.net = net\n","        for (name, module) in self.net.named_modules():\n","            if isinstance(module, nn.ReLU):\n","                module.register_backward_hook(self.backward_hook)\n","        self.net.eval()\n","\n","    @classmethod\n","    def backward_hook(cls, module, grad_in, grad_out):\n","        \"\"\"\n","        :param module:\n","        :param grad_in: tuple\n","        :param grad_out: tuple\n","        :return: tuple(new_grad_in,)\n","        \"\"\"\n","        return torch.clamp(grad_in[0], min=0.0),\n","\n","    def __call__(self, inputs, index=None):\n","        \"\"\"\n","        :param inputs: [1,3,H,W]\n","        :param index: class_id\n","        :return:\n","        \"\"\"\n","        self.net.zero_grad()\n","        output = self.net(inputs)[0][0]  # [1,num_classes]\n","        if index is None:\n","            index = np.argmax(output.cpu().data.numpy())\n","        target = output[0][index]\n","\n","        target.backward()\n","\n","        return inputs.grad[0]  # [3,H,W]"],"metadata":{"id":"M4r3HwxRSVte","executionInfo":{"status":"ok","timestamp":1678558530004,"user_tz":-360,"elapsed":342,"user":{"displayName":"Miraj Hossain Shawon","userId":"08980054486899795507"}}},"execution_count":148,"outputs":[]},{"cell_type":"code","source":["\n","\n","import argparse\n","import os\n","import re\n","\n","import cv2\n","import numpy as np\n","import torch\n","from skimage import io\n","from torch import nn\n","from torchvision import models\n","import sys\n","sys.path.append(\"..\")\n","\n","\n","from PIL import Image\n","import torchvision.transforms as transforms\n","\n","\n","def get_net():\n","\n","    net = ResNet(BasicBlock, [2, 2, 2, 2], [[1, 1, 2], [1, 2], [2]], num_classes=2)\n","\n","    return net\n","\n","\n","def get_last_conv_name(net):\n","    \"\"\"\n","    :param net:\n","    :return:\n","    \"\"\"\n","    layer_name = None\n","    for name, m in net.named_modules():\n","        if isinstance(m, nn.Conv2d):\n","            layer_name = name\n","    return layer_name\n","\n","\n","def prepare_input(image):\n","    image = image.copy()\n","    means = np.array([0.485, 0.456, 0.406])\n","    stds = np.array([0.229, 0.224, 0.225])\n","    image -= means\n","    image /= stds\n","\n","    image = np.ascontiguousarray(np.transpose(image, (2, 0, 1)))\n","    image = image[np.newaxis, ...]\n","\n","    return torch.tensor(image, requires_grad=True)\n","\n","\n","def gen_cam(image, mask):\n","    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n","    heatmap = np.float32(heatmap) / 255\n","    heatmap = heatmap[..., ::-1]  # gbr to rgb\n","\n","    cam = heatmap + np.float32(image)\n","    return norm_image(cam), (heatmap * 255).astype(np.uint8)\n","\n","\n","def norm_image(image):\n","    image = image.copy()\n","    image -= np.max(np.min(image), 0)\n","    image /= np.max(image)\n","    image *= 255.\n","    return np.uint8(image)\n","\n","\n","def gen_gb(grad):\n","    grad = grad.data.numpy()\n","    gb = np.transpose(grad, (1, 2, 0))\n","    return gb\n","\n","\n","def save_image(image_dicts, input_image_name, network, output_dir):\n","    prefix = os.path.splitext(input_image_name)[0]\n","    for key, image in image_dicts.items():\n","        io.imsave(os.path.join(output_dir, '{}-{}-{}.jpg'.format(prefix, network, key)), image)\n","\n","\n","\n","\n"],"metadata":{"id":"1cS3ZZxHpYFp","executionInfo":{"status":"ok","timestamp":1678558532735,"user_tz":-360,"elapsed":2,"user":{"displayName":"Miraj Hossain Shawon","userId":"08980054486899795507"}}},"execution_count":149,"outputs":[]},{"cell_type":"code","source":["# img = io.imread(args.image_path)\n","img = Image.open('/content/drive/MyDrive/Data/0/20051019_38557_0100_PP.tif').convert(\"RGB\")\n","trans = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224)]\n",")\n","img = trans(img)\n","img.save(\"/content/drive/MyDrive/Data/rgb.jpg\")\n","img = np.float32(cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR)) / 255\n","# img = np.float32(cv2.resize(img, (224, 224))) / 255\n","inputs = prepare_input(img)\n","print(inputs.type())\n","image_dict = {}\n","net = get_net()\n","# Grad-CAM\n","layer_name = get_last_conv_name(net) #if args.layer_name is None else args.layer_name\n","grad_cam = GradCAM(net, layer_name)\n","\n","mask = grad_cam(inputs)  # cam mask\n"],"metadata":{"id":"5yMJ2DVaDKHx","executionInfo":{"status":"error","timestamp":1678559012570,"user_tz":-360,"elapsed":579,"user":{"displayName":"Miraj Hossain Shawon","userId":"08980054486899795507"}},"colab":{"base_uri":"https://localhost:8080/","height":363},"outputId":"04f5b77d-9dc4-469f-bee3-7db3e8e0e33d"},"execution_count":154,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.FloatTensor\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-154-6541592eda70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mgrad_cam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradCAM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# cam mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-152-49c2c369fbf8>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# select first tensor from the tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-102-34ebcbf31253>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 3, 1, 224, 224]"]}]},{"cell_type":"code","source":[],"metadata":{"id":"yE6r_L4C4Oz0","executionInfo":{"status":"ok","timestamp":1678557506631,"user_tz":-360,"elapsed":360,"user":{"displayName":"Miraj Hossain Shawon","userId":"08980054486899795507"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"16264179-81d5-455f-c8c1-3bd92026eb31"},"execution_count":133,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.FloatTensor\n"]}]},{"cell_type":"code","source":["image_dict['cam'], image_dict['heatmap'] = gen_cam(img, mask)\n","grad_cam.remove_handlers()\n","# # Grad-CAM++\n","# grad_cam_plus_plus = GradCamPlusPlus(net, layer_name)\n","# mask_plus_plus = grad_cam_plus_plus(inputs, args.class_id)  # cam mask\n","# image_dict['cam++'], image_dict['heatmap++'] = gen_cam(img, mask_plus_plus)\n","# grad_cam_plus_plus.remove_handlers()\n","\n","# GuidedBackPropagation\n","gbp = GuidedBackPropagation(net)\n","inputs.grad.zero_()\n","grad = gbp(inputs)\n","\n","gb = gen_gb(grad)\n","image_dict['gb'] = norm_image(gb)\n","# cam_gb = gb * mask[..., np.newaxis]\n","# image_dict['cam_gb'] = norm_image(cam_gb)\n","\n","save_image(image_dict, os.path.basename('/content/drive/MyDrive/Data/0/20051019_38557_0100_PP.tif'), 'Res', '/content/drive/MyDrive/Data/images')"],"metadata":{"id":"IRRT6RGoFLJJ","executionInfo":{"status":"ok","timestamp":1678554719396,"user_tz":-360,"elapsed":14,"user":{"displayName":"Miraj Hossain Shawon","userId":"08980054486899795507"}}},"execution_count":96,"outputs":[]},{"cell_type":"code","source":["inputs"],"metadata":{"id":"QLzRoTXHHL9H","executionInfo":{"status":"ok","timestamp":1678558664313,"user_tz":-360,"elapsed":354,"user":{"displayName":"Miraj Hossain Shawon","userId":"08980054486899795507"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b434e786-5db3-4880-f6c9-fd0251123032"},"execution_count":151,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[-2.1008, -2.1008, -2.0837,  ..., -2.1008, -2.1008, -2.1008],\n","          [-2.0837, -2.1008, -2.0837,  ..., -2.1008, -2.0837, -2.0837],\n","          [-2.0837, -2.0837, -2.0837,  ..., -2.1008, -2.0837, -2.1008],\n","          ...,\n","          [-2.0837, -2.0837, -2.0665,  ..., -2.0837, -2.1008, -2.0837],\n","          [-2.0837, -2.0837, -2.0665,  ..., -2.0837, -2.0837, -2.0837],\n","          [-2.0837, -2.0837, -2.0837,  ..., -2.0837, -2.0837, -2.0837]],\n","\n","         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n","          ...,\n","          [-2.0182, -2.0357, -2.0182,  ..., -2.0182, -2.0357, -2.0182],\n","          [-2.0182, -2.0357, -2.0182,  ..., -2.0182, -2.0182, -2.0357],\n","          [-2.0182, -2.0182, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n","\n","         [[-1.7870, -1.7870, -1.7696,  ..., -1.7870, -1.7870, -1.7870],\n","          [-1.7696, -1.7870, -1.7696,  ..., -1.7870, -1.7696, -1.7696],\n","          [-1.7696, -1.7696, -1.7696,  ..., -1.7870, -1.7696, -1.7870],\n","          ...,\n","          [-1.7696, -1.7696, -1.7522,  ..., -1.7696, -1.7870, -1.7696],\n","          [-1.7696, -1.7696, -1.7522,  ..., -1.7696, -1.7696, -1.7696],\n","          [-1.7696, -1.7696, -1.7696,  ..., -1.7696, -1.7696, -1.7696]]]],\n","       requires_grad=True)"]},"metadata":{},"execution_count":151}]},{"cell_type":"code","source":[],"metadata":{"id":"jNpWBL-ocP5e","executionInfo":{"status":"ok","timestamp":1678554719397,"user_tz":-360,"elapsed":14,"user":{"displayName":"Miraj Hossain Shawon","userId":"08980054486899795507"}}},"execution_count":96,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Eqqt42ypcipY","executionInfo":{"status":"ok","timestamp":1678554719398,"user_tz":-360,"elapsed":15,"user":{"displayName":"Miraj Hossain Shawon","userId":"08980054486899795507"}}},"execution_count":96,"outputs":[]}]}